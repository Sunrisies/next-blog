前文遗留了一个问题，如果网络情况不佳，TCP 协议会如何处理呢？我们先来看一个例子。

大视频在不同的网络上传
-----------

还是上文提到的那个 1.5G 视频上传的例子。为什么我会一直关心这个视频上传的例子呢？是因为确实曾经遇到了一个这样的问题，当时在生产环境上传 1.5G 的视频中途报出异常，导致上传不成功，但从日志和异常信息都没看出端倪。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8164cbe50b2945baac3293b214813fb2~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1071&h=420&s=42463&e=png&a=1&b=6a36d2)

因为打的日志不多，生产环境不太好调试，于是尝试在测试环境来复现问题，试图发现问题所在。奇怪的是，测试环境上传同样的视频却没有问题。因为没有解决问题的思路，只好用`tcpdump`工具(tcpdump是一款基于命令行的网络协议分析工具，它可以捕获和分析网络数据包。)对两个环境上传视频的流量进行抓包。

我们的服务器分别在测试环境和生产环境部署，这两个服务运行在同样的容器里面，但是两个环境对应的网络环境肯定是不一样的。得到了抓包文件后，我们使用`Wireshark`(Wireshark是一款开源的网络协议分析工具，它可以在计算机网络中捕获数据包并对其进行分析)打开这个文件。

测试环境抓包的结果用`Wireshark`统计图展示的方式如下图所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f7736d72e1a14ed7a34f81d68062d6e1~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=3272&h=1670&s=339739&e=png&b=b2d7fc)

横坐标是时间，纵坐标是发包成功的个数。可以发现，1.5G 的视频在 280s 内能传输完，包传输的速度大概在 500个/s，整体比较稳定。

生产环境网络抓包的结果用`Wireshark`统计图展示的方式如下图所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dbc0b9c36a4a43968996ae1732f9195e~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=2072&h=961&s=443872&e=png&a=1&b=fdfdfd)

同样的，横坐标是时间，纵坐标是发包成功的个数。可以看到，上传到线网环境需要 310 多秒，而且传输的速度起伏比较大，没有测试环境那么稳定；而且要特别注意，靠近横坐标线的上方有一些红色的小柱状，从开始的时间一直延续到上传结束，这些包是传输时`因为错误重传`的包。

通过对比传输的过程，我们将排查问题的方向放在了传输时间的不同上。上传的都是同一个视频，传输的包整体大小是一样的，只是正式环境数据需要更多的时间，那会不会因为超时异常呢？果不其然，我们 Review 应用程序代码，发现其在对请求进行鉴权的过程中，对请求的时间戳做了不超过 300s 的限制。如果上传的视频文件时间超过 300s，那么这个请求的时间戳也就超时了，请求鉴权就会失败。

引起正式环境上传速度更慢的原因可能是网络带宽更低，也可能是网络更拥塞，或者是正式环境应用处理效率低等原因。但我们可以排除正式环境应用处理效率低的原因，因为用的是一模一样的Docker环境；另外正式环境的带宽和测试环境比起来也没有更低。而且从我们抓包的情况来看，正式环境发生了很多的丢包重传，这意味着上传视频的网络更堵！

可见网络传输的环境问题是不能忽略的，网络环境的不同可能会造成意想不到的问题。就像导航的地图上复杂的路况一样，计算机网络地图也是特别复杂的；从这个事件出发，本文主要来探讨一下`网络拥塞处理机制`。

复杂的网络道路——易拥塞
------------

计算机网络就像承载运输车辆的运输网络（包括高速公路、岔路口、国道和一般的公路）一样，包括各种终端、网线、路由器和交换机等。数据包从一个终端到大洋彼岸的另一个终端，可能会通过各种介质，比如无线 Wi-Fi、双绞线、海底光纤等。

不同的通道，比如双绞线和光纤的传输速率会不一致，对于一个数据包，它前面的比特到达一个路由器之后会等待这个包后面的比特的到达，整个包都到达这个路由器之后再通过出链路传递到下一站。如果到达路由器的数据包很多，那么它们在路由器上面还需要排队转发。当排队时间长的时候可能会出现 ACK 超时情况；甚至如果一个路由器上面的包排队数量超过了路由器的队列大小，后来的包则会被丢弃。

因为资源有限，大量的负载很容易造成排队超时，溢出丢弃。因为有丢包重传，计算机网络和普通公路比起来拥堵更甚，当拥塞和丢包发生的时候，整个网络会出现很多重传的包的流量。若出现拥塞而没有得到有效控制，拥塞情况就会变更严重，**整个网络吞吐量不增反减**。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a2640384a2749e4be1456f1021f712b~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=832&h=450&s=93618&e=png&b=474747)

为了避免这种坏事情的发生，我们自然能想到，如果发送方能感知到网络拥塞并放缓发送包的速度，那么拥塞就能缓解了。那么怎么使得感知网络拥塞呢？直观上，当发送方出现包超时的时候，往往就意味着网络已经拥塞了，此时发送方可以采取一些放缓措施来避免拥塞。

TCP 发送端拥塞控制机制采用了`一套具体的算法`，让我们一起看下具体是怎样的吧。

发送方的拥塞控制算法
----------

通过[前面第 3 节的“流量控制”章节](https://juejin.cn/book/7209116225988165667/section/7209116226386133032 "https://juejin.cn/book/7209116225988165667/section/7209116226386133032")，我们已经知道发送方使用发送窗口来发送数据。发送窗口的大小是一个变量`swnd`，它是另外两个变量的函数：min(cwnd，rwnd)min(cwnd，rwnd) min(cwnd，rwnd)。这里引入一个新的变量：**拥塞窗口大小**`cwnd`，是发送方维护的一个状态变量，它根据**网络的拥塞程度动态变化**。假设接收窗口`rwnd`很大，则发送窗口的大小主要受`cwnd`的影响。在实际网络上，`cwnd`在影响发送窗口大小上确实发挥了主要作用。

你一定很好奇，那发送方维护的`cwnd`是怎么变化的呢？

### 开始试探网络

#### 1\. 慢开始——从小窗口加速到门限值

连接建立之后，`cwnd`的值从一个很小的值开始，假设`cwnd`的初始窗口大小是 1（MSS，一个 TCP 数据包），等收到这个包的 ACK 的时候，`cwnd`变为 2，再然后收到这 2 个 ACK 的时候，`cwnd`变为 4...，按照轮次来看，发送窗口大小的变化呈现指数级增长，虽然初始值比较小，但`cwnd`增长的速度比较快。（这个过程可以 check 后面图所示的第一个`慢开始`方块。）

这样增长到什么时候呢？假设 cwnd 值增长到某个阈值，阈值使用变量`ssthresh`表示。每个连接的`ssthresh`初始默认是个无穷大的值，但是内核会 cache 对端 ip 上次的`ssthresh`（大部分时候两个 ip 或者网段之间的拥塞窗口大小变化不大）。系统认为，上一次的历史带宽则是这次的期望带宽。直观上，`ssthresh`的值和网络连接的期望带宽是一致的，达到 ssthresh 值则意味着这个网络连接的带宽也处于比较饱和的状态。所以，带宽越大则慢开始阶段能增长到更大的`ssthresh`值，比如`10Mbps`带宽连接的 ssthresh 值可能是`10Kbps`的一千倍。

当`cwnd`到达`ssthresh`值的时候，如果还能没有感知到超时和重传，那么将会进入另外一个**慢增长**的阶段，称之为**拥塞避免**。

#### 2\. 拥塞避免——试探性地避免拥塞

这个阶段其实含有试探的意思。虽然已经到了期望带宽了，但因为道路还是畅通的，那发送方还是再慢慢增加一下`cwnd`，看看网络是否会出现拥塞呢。就像我们想要淌过一条河的时候，当水盖过腰部的时候我们得慢慢地试一下水的更深处。

所以，到达`ssthresh`的时候，`cwnd`的大小开始变为线性加速，当`cwnd`窗口内发出的包都收到 ACK 之后，`cwnd`窗口的值才加 1。

我们可以使用`ip tcp_metrics show |grep ssthresh`来查看一下缓存连接的 `ssthresh`和`cwnd`值：

     #sudo ip tcp_metrics show |grep ssthresh
    a age 701140.188sec rtt 4000us rttvar 5000us ssthresh 117 cwnd 9
    b age 3053324.200sec rtt 7500us rttvar 15000us ssthresh 150 cwnd 149 
    c age 38.960sec rtt 7500us rttvar 15000us ssthresh 57 cwnd 57
    d age 55.680sec rtt 7500us rttvar 6000us ssthresh 435 cwnd 434 
    

上面我使用 a、b、c、d 分别表示四个不同的 IP 目的地，可以看到上面四个不同的目的地 IP 的`cwnd`和`ssthreash`都各不相同，它们的单位都是包的个数：

*   到 a 的 ssthresh 值为 117 个包，当前 cwnd 为 9 个包，cwnd 还有很大增长空间；
    
*   到 b 的 ssthresh 值为 150，当前 cwnd 为 149，目前 cwnd 接近 ssthresh；
    
*   到 c 的 ssthresh 值为 57，当前 cwnd 为 57，目前 cwnd 等于 ssthresh；
    
*   到 d 的 ssthresh 值为 435，当前 cwnd 为 434，ssthresh 值很大，目前 cwnd 也接近 ssthresh。
    

### 当拥塞发生时

在拥塞避免阶段，窗口还是在慢慢增大，如果不丢包重传，网络吞吐量就还在增长。但是网络的容量毕竟是有限的，如果只增不减，网络一定会出现拥塞排队或者丢包。如果这样了还不控制，则要出现网络吞吐量整体下滑的坏现象！

#### 1\. 超时拥塞——急刹

从发送方来看，当出现 ACK 超时时，则代表着拥塞事件的发生，那么此时拥塞处理算法就要做出相应的处理。

在 Reno 版本的算法里，将`ssthreash`设置为当前拥塞窗口值`cwnd`的一半，并且将`cwnd`设置为 1，重新进入慢启动阶段，可以 check 后面曲线图所示的`超时重传`事件开始的曲线。这是不是也有点像开车时候的急刹车呢～

#### 2\. 快速重传拥塞——点刹

另外，当 ACK 被快速重传的时候也往往意味着有丢包事件的发生，但不一定是非常拥塞的网络导致的。快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 ACK 超时那么强烈，那么这也意味着可以快速恢复了。将`cwnd`和`ssthresh`都设置为当前`cwnd`的一半，然后进入拥塞避免阶段。就像驾车在路上行驶的时候，如果遇到前面的车辆还比较远就可以不用踩死刹车，点刹慢慢刹车然后看情况再加速即可。

这就是快速重传的拥塞处理，后来的 Reno 算法版本提出了这个改进。虽然对于拥塞处理机制不是必须的，但却能带来网络性能上的改进，可以 check 曲线图的快重传事件开始的曲线。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ca4203a29d94453adf7d63b6e04093b~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=2111&h=1177&s=236054&e=png&a=1&b=fefefe)

### 算法小结——拥塞控制状态机

通过上面几个步骤和应对两种拥塞事件的策略，由 TCP 发送端主导的拥塞控制机制就像一个完备的状态机一样，孜孜不倦地工作着！如下图所示的状态图，上面三个事件发生的时候，`cwnd`和`sshthresh`的值会根据规则重新计算，且进入如箭头所示的状态和过程。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7aab4c8e19994c4e9383ac67cfa27691~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1134&h=402&s=43730&e=png&b=ffffff)

那现在留一个问题给你思考，如果在慢开始阶段出现 ACK 超时事件，状态会如何改变呢？

总结
--

本文首先通过一个大文件上传的例子，让我们看到数据传输的过程也可能引起一些问题，如果能正确使用工具对于排查问题很有帮助。然后，我们讨论了如果发送方能感知到网络拥塞并放缓发送包的速度，那么就能很好地控制拥塞，并且详细讨论了拥塞控制的方法。

另外，除了发送方感知拥塞外，TCP 协议也可以采用从**网络核心**去感知拥塞，并且设置到 TCP 包的头部字段来作为控制拥塞的机制。虽然在一些网络中部署并得到了使用，不过不像发送方控制的拥塞机制这么流行，感兴趣也可以找资料多了解一些。

关于本文的相关问题和思考，欢迎在评论区留言哦～
在上面的文章中，我们着重分析了 TCP 连接的理论知识，可能有同学开始手痒痒，想上手实践一把，毕竟“光说不练假把式”嘛！因此，本篇文章咱们就转向 TCP 连接实战，而连接正常的流程就是协议在常规场景下的逻辑，我们也很熟悉了。本文会分享连接异常的几个经典案例，这么安排主要有以下三个目的。

1.  进一步巩固前面的理论知识。
2.  了解实际网络连接可能出现的各种异常状况。
3.  帮助养成更好的网络连接意识。

那下面就一起来看一下 TCP 连接异常的几个案例吧！

经典案例 1：连接超时
-----------

我曾经遇到过一个问题，事情是这样的：我有一个同步数据的应用程序，需要连接很多 `HTTP 服务`去同步一些数据到本地系统；但有时由于网络问题，连接到这些 `HTTP 服务`会出现连接超时的告警；当同步数据的客户端创建连接超时了，我发现常常是在 127s 左右后发出告警的。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2a6d95e91d0f4d36a6e023b97308e12e~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=864&h=528&s=41854&e=png&a=1&b=4473c4)

我很好奇：`为什么一般会在 127s 左右发出告警？`所以，就带着疑问去研究了一下，主要是往 **TCP 重传**的方向去思考。

我们知道，如果请求发出去，在一段时间内没有收到响应就会重传消息。那么，会在多久时间后重传呢？TCP 将从发出一个包开始到接收到对应的`ACK 回执`所需要的时间定义为 **round-trip time** **（简称** **RTT** **）** 。网络的情况总是在变化的，所以 RTT 也是在动态变化的，内核会采样 RTT 的数据，用采样的 RTT 计算出一个**重传的标准时间**：**retransmission timeout（简称 RTO）** 。

现在通用的 Linux 内核的`RTO`的计算一般参考 RFC-2988 标准（下图左边），下图右边是一个具体代码实现，在`net/ipv4/tcp_input.c 文件中。`你如果感兴趣的话，可以点开下图 check 一下或直接在网上搜索相关的 RFC 标准和代码。这里我就不再赘述了，你只需要知道各个平台在实现网络协议时都会遵从统一的规范和标准就行了。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5127f5c4b2f045b985ccb5cbfe190352~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1108&h=790&s=560322&e=png&a=1&b=fcfcfc)

如上图红框所示，因为服务器所在网络状况良好，`RTT`不会超过几毫秒，所以`RTO`就是规定的最小值 1s。

另外，重传几次呢？如果当前网络状态确实不好，想在后面的时间再重试呢？这就要用到**重试机制**，常用的重试策略有如下两种。

*   **第一种，`固定时间间隔`尝试策略**。如下图的每隔 1s 重试一次，一共重试 2 次。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/daafe4b4f13743fcbbb342ec52c10748~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=518&h=108&s=10645&e=png&a=1&b=8299ce)

*   **第二种，`指数时间间隔`尝试策略**。如下图的每隔 1、2、4s……重试一次，一共重试 6 次。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7ffd2662284147c89b74a54eb72aec30~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=832&h=112&s=15259&e=png&a=1&b=8a9fd1)

关于重传的时机和策略，我这里做了个小总结，如下图所示，你可以点开大图再次 check 一下。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e2af06507c684771930e0bb2e1c88476~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1286&h=558&s=119300&e=png&b=477ad1)

**类 Linux 系统的 SYN 包重传一般使用指数时间间隔尝试策略**，Syn 重传的次数定义在变量 `/proc/sys/net/ipv4/tcp_syn_retries` 里面，可以看到重传次数为 6。

    cat /proc/sys/net/ipv4/tcp_syn_retries
    6
    

超时无应答之后，因为系统设置的重传次数是 6、`RTO` 为 1s、使用指数时间间隔尝试策略，所以依次重传等待的秒数为 1、2、4、8、16、32，最后一次重传后将等待 64s，而后就不再尝试去建立连接了。**这些等待时间加起来大约就是 127s 左右**。

“为何超时时间是 `127s`”的推论总结就如下图所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/64488c99250b4e5485c37af2c2dd3006~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1042&h=584&s=69476&e=png&a=1&b=4776c8)

看，前面留有疑问的那个问题这不就解决了嘛！撒花撒花～

经典案例 2：资源不足
-----------

让我们继续往下讨论 TCP 网络连接异常的另外一个经典案例——资源不足。

有一次，我发现通过客户端访问我们部署的 `Web 服务` 不可达了，telnet 命令连接服务器的 80 端口不通。登录到 Web 服务所在的机器上，使用 `netstat` 命令查看 80 端口的网络连接，如下面板：

    # netstat ｜grep 80
    Proto Recv-Q Send-Q Local Address   Foreign Address   State       PID/Program name    
    tcp        0      0 0.0.0.0:80        0.0.0.0:*       LISTEN      26523/java     
    

上面显示的面板有一条 tcp 连接，处于`LISTEN`状态，端口正是 80。同时，也发现有很多要和 80 端口建立连接的请求处于`Sync-RCVD`状态，如下：

    tcp     0    0 0.0.0.0:80     9.134.1.100:34344     Sync-RCVD      26523/java     
    tcp     0    0 0.0.0.0:80     9.134.1.100:34398     Sync-RCVD      26523/java     
    

为什么客户端连接还处于`半连接`状态，但无法正确地建立连接呢？

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7b683026b2104b96a6b31dfeca57c0ea~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=594&h=118&s=15828&e=png&a=1&b=487ad1)

最有可能发生异常的地方是我们的 Web 程序，查看 Web 程序的日志，发现 Web 程序在最近的一段时间里出现过 **`Out of Memory（OOM）`** **的异常。** 这个 Web 程序运行在 Java 虚拟机里面，设置的最大虚拟内存被用完了，导致无法分配更多的内存，所以会抛出 `OOM` 这样的异常。

让我们再回忆一下上一节讲的连接建立的过程，如下图：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7a6cee0ee00246eaa678e612ee7f34d4~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=669&h=433&s=93342&e=png&b=ffffff)

服务端收到客户端发起连接的第一个`SYN 包`后，转为`Sync-RCVD`状态，此时连接尚未完全建立，被操作系统放在`半连接队列`中；等到第3步骤再次收到客户端发送过来的Ack包时，连接才算完全建立，而连接也会被放置到`全连接队列`中，Web程序就能通过调用accept函数从这个队列中获得一个新连接了。 但是此时 Web 程序内存不足，虚拟机正在进行疯狂的GC，整个Web程序完全处于静止状态，没法及时将连接从`全连接队列`中取出来。越来越多的客户端连接上来时，`全连接队列`就满了，同样的道理，`半连接队列`也会满。如果此时再收到客户端发过来的`SYN 包`，操作系统选择不理会，直接不发送`SYN+ACK 包`响应，导致客户端的状态维持在`Sync-Sent`状态，无法变为`Established`。这导致我们看到的现象就是：连接不通了。

整个排查过程总结如下图所示，你可以点开大图再次 check 一下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/60e9a463aa5d409ca445fcc9f312ba65~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=754&h=592&s=97461&e=png&a=1&b=fefefe)

问题的原因找到了，但是要怎样来解决这个问题呢？

一般来说，直接**重启服务**就能释放内存、解决问题，但这里**更关键的是要找到导致内存`OOM`的原因**。如果是正常的现象，比如虚拟机内存确实设置得太小，则应该调大内存；如果是其他内存泄露问题导致的`OOM`，则需要找到内存泄漏的原因，解决 Bug，重新部署服务上线。

系统资源不足，不仅是内存不足，还包括磁盘空间不足等都容易引起连接异常的问题。当我们在现实排查问题的时候遇到疑难的问题时，一定要往这方面想，`是不是某方面资源耗尽了导致连接异常？！`如下图所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bbd84663df374ecc8b21d12aa91a98c5~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1310&h=526&s=152880&e=png&a=1&b=396cc4)

经典案例 3：Syn Flood 攻击
-------------------

现在，我们继续往下讨论连接异常的经典案例 3：Syn Flood 攻击！

你一定听说过闻名遐迩的`洪泛 Flood 攻击`吧，即`DoS 或 DDoS 攻击`。攻击方操纵一批“僵尸机器”对服务发起`洪泛 Flood 攻击`，使之无法正常地响应业务请求。

“僵尸机器”分布式地发起大量的连接请求`SYN`包后，服务器回应`ACK+SYN 包`。每发出一个`ACK+SYN 包`，内核都要将这个包缓存在`半连接队列`里，直到收到第三次握手的`ACK`包，再将`半连接队列`里对应的包转移出去。

“僵尸机器”却对回应的`ACK+SYN 包`不再做出任何响应，**使得服务器内核的半连接队列溢出，其他正常的业务连接无法建立连接**。

然而雪上加霜的是，如果发出的`ACK+SYN 包`一直没有收到 `ACK 回执`，还会被重传。`ACK+SYN 包`使用固定时间间隔策略重试，重传次数是定义在`/etc/sysctl.conf`文件里的`tcp_synack_retries`，默认值为 5。

上述详细的交互过程如下图所示，可以点开大图 check 一下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6164061713743cd87db1b004dade094~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1610&h=742&s=521424&e=png&a=1&b=ced5e8)

那应该如何应对洪泛攻击呢？

如果我们**将** **`tcp_synack_retries`** **的值设置得更小**，比如 0，这样`半连接队列`中的包超时后就会直接丢弃，能提升队列的使用效率。

同样的，如果我们**加大** **`半连接队列`** **的长度**也可以容纳更多半连接。`半连接队列`的大小设置使用变量`tcp_max_syn_backlog`，默认值是 1024，可以将这个值设置到更大，比如 4096。

不过，需要注意的是，修改`tcp_synack_retries`默认值存在两方面的问题。

*   一方面，这个方式可能是有副作用的，比如当网络状况确实是不太好，则会导致连接快速失败。好在一般网络情况下这种情况是很少见的。
    
*   另一方面，这个方式并不能完全解决`SYN Flood 攻击`的问题，如果同时发起的连接很多，`半连接队列`将很快占满。在等待超时的`RTO`时间内，如果半连接队列没有空余位置，则正确的业务请求也都会被丢弃。
    

而通过修改`tcp_max_syn_backlog`的默认值的方式也只能稍微缓解一下队列，更大并发的攻击也会很快填满`半连接队列`。

这些处理方式围绕着**提高队列的阈值和使用效率**的目标，总结如下图所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ced8cdb302c54b5cb44fa8f052db62ef~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=746&h=478&s=83500&e=png&a=1&b=fefefe)

上面提到的方法还是有缺陷的，但办法总比困难多，总还有更好的办法！**`SYN Cookie` 是应对 `Syn Flood 攻击`的一种行之有效的方法**。

在使用`SYN Cookie`的场景下，`半连接队列`满了之后， 半连接状态的处理不再通过`半连接队列`。那是怎么做的呢？**内核直接回应 `SYN+ACK 包`给客户端**，巧妙的地方就在于这个`SYN+ACK 包`。原本`SYN 序列号`会是一个随机数，但在`SYN Cookie`场景下，**使用一个特殊编码的`SYN`序列号，将源 IP、目的 IP、源端口、目的端口和包发送的时间等信息编码在** **`SYN`** **序列号里面**。

等第 3 次握手的`ACK 包`收到之后，系统就可以解码`ACK 包`得到对应`SYN 序列号`的信息，如果这些信息都准确合理，就能判断知道这个连接是合法的。对于`Syn Flood 攻击`的请求，即使“僵尸机器”一直不回应第 3 次握手的`ACK 包`也不会影响`半连接队列`；对于正确的业务请求，收到客户端的`ACK`包后，验证其是合法的，则能建立连接。

**要开启** **`SYN Cookie`** **，需将变量** **`net.ipv4.tcp_syncookies`** **设置为 1 。**

当然，还有一些别的应对方式，比如 SYN Cache 技术。系统在收到一个 SYN 报文时，在一个专用 HASH 表中保存这种半连接信息，直到收到正确的回应 ACK 报文再分配 TCB(全称是Transmission Control Block，它是操作系统内核中用于维护TCP连接信息的数据结构。它包含了TCP连接的各种状态信息，如序列号、窗口大小、超时计数器等)，这个开销远小于 TCB 的开销。

`SYN Cookie`等方式的总结如下图所示，你可以结合图再 check 和梳理一下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/83e22d69734f45798be5f13bfa3ded5c~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1090&h=460&s=64332&e=png&a=1&b=000000)

总结 & 分享
-------

本文分享了 TCP 连接异常的 3 个经典案例，分别是资源耗尽、正常网络的连接超时和网络攻击造成的连接超时。这 3 个经典案例可以说是涵盖了连接相关的各种知识点，现在你是否对 TCP 连接有了更深的认识了呢？

最后呢，我还想分享一个我曾经遇到过的很诡异的场景，服务器发出`Connection reset by peer`的告警，这个告警说明服务器收到了带有`RST`标记的`TCP 报文`。浏览器页面打开后很快关闭就有可能引起这样的告警。我们知道，`RST`标记位用于强制断开连接，如果服务器在响应数据时，客户端正好强制关闭了连接，则服务将发出这样的告警。但是，如果出现大量的情况，就要注意了，可能是网络不稳定引起的。

你还遇到过哪些 TCP 连接异常的场景呢？可以在评论区留言，一起分享一下吧！
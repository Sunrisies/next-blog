上一章我们讲了计算机网络的层级，并且知道了每一层的作用，其实对于我们来说，我们真正需要了解的就两层，一个是**应用层**，一个是**传输层**。

**应用层的 HTTP、传输层的 TCP**，这俩协议是用得最多的，基本上霸占了“皇后”和“贵妃”的位置，而 HTTP 又是基于 TCP 实现的，那我们就追其根溯其源，剥其衣脱其裳，来彻底了解下这位面试官最喜欢打听的协议吧。

TCP 可靠传输的实现原理
-------------

上一章我们说过：**TCP 的传输是可靠的**。那么，这个“可靠”是啥意思呢？其实它包含两个点：

1.  传输的数据`没有差错`；
2.  传输的数据`不会丢失`。

有人说，你这不废话吗？没有差错肯定就不会丢失啊，第 1 点包含了第 2 点啊。

非也！

我们举个例子，我一秒给你发 100 条信息，并且全发到了，这是没有差错；但是你来不及看完，也就是有漏看，这就是丢失了。

所以，我们可以定义得更精简一点：**传输的数据没有差错并且全部被处理**。

这怎么可能呢？网络信号肯定有不好的时候，比如隔壁有人下载东西下载得太猛把网下欠费了又不去缴费，那这不就丢失了？你怎么保证可靠？

可以的，我们只需要保证两点：

1.  传输出错的数据进行重传；
2.  控制传输速度，让接收方来得及处理。

这样，即使原来不可靠，也会变得可靠了。

要实现这两点，我们要了解以下几个协议。

### 超时重传协议

> 发送方在发送数据之后的规定时间内，如果没有收到接收方的确认，则重新传送数据。

现在假设 A 向 B 发消息，如果网络正常，就是 A 向 B 发送消息，B 正常收到。

但是如果网络异常呢？A 向 B 发送之后，A 怎么知道 B 是否收到了呢？

这就需要 B 在收到 A 的消息后，向 A 发送一个确认信号，A 收到了 B 的确认信号，才认为 B 正确地收到了 A 发送的消息。

所以，如果网络正常，那么流程就变为：

1.  A 向 B 发消息，并等待 B 的确认；
2.  B 收到 A 的消息，发送确认消息给 A；
3.  A 收到 B 的确认消息，认为 B 正常收到了，继续发送下一个消息。

那么，如果 A 迟迟没有收到 B 的确认消息呢？比如，双方约定了一个时间 T，A 在发送消息后，经过时间 T 还没有收到 B 的确认消息，那么 A 还继续等吗？

不等了！此时 A 就认为 B 没有收到自己发送的消息，于是就重新发送一次，直到收到 B 的确认消息为止。

这就叫做**超时重传**。那么这个时间又是多少呢？

我们假设，A 发送消息到 B 需要的时间为 t1，B 处理消息需要时间为 t2，B 发送确认消息到 A 需要的时间为 t3，那么这个超时时间 T 肯定要大于 t1+t2+t3。而且考虑到通用性，我们应该计算多次 t1+t2+t3，并且取它们的平均值，而 T 就要大于这个平均值。

当然，有人说了，你这也不准啊，网络可能有时候很差，有时候很好，你这怎么决定呢？

旨哉斯言！

所以，我们要`动态计算`这个超时时间，我们在[第 14 章](https://juejin.cn/book/7196580339181944872/section/7196591134489968692 "https://juejin.cn/book/7196580339181944872/section/7196591134489968692")讲过`自旋锁`，自旋锁可以根据具体情形进化为自适应自旋锁。这里也是一样的道理，我们可以根据当前情形动态计算超时时间 T，比如：根据最近的 20 次传输时间取平均值。

其实，核心就是**动态计算**，而不是固定死的一个值。

当然，超时重传这个操作 TCP 已经帮我们做好了，我们在 API 层是无感知的，无脑调用 API 就行。所以也叫做**自动重传递协议，术语就是 ARQ（Automatic Repeat reQuest）**。

ARQ 保证我们的数据是无差错地传输到另一端，那么，怎么保证另一端能来得及处理呢？

这就要说到停止等待协议。

### 停止等待协议

> 发送方会调整发送速度，来等待接收方处理完之后，再进行发送。

其实，我们上文已经说过了，A 发送一条消息之后，直到收到 B 的确认消息，才会继续发送下一条消息，就好像是 **A 等着 B 似的**，这就叫**停止等待协议**。这样一来，B 总是在自己处理完一条消息之后才发送确认信号给 A，A 总是在 B 处理完一条消息之后才发送下一条消息给 B，说白了就像一条隧道，A 开过去，B 再开过来，A 再开过去，如此循环。

等等，这不对劲啊！我们的 TCP 是**全双工**啊，你这样活脱脱地把它完成了单工通信了，这岂不是白白浪费资源吗？

比如 B 在发送确认消息到 A 的过程中，A 就干等着？A 在发送消息给 B 的过程中，B 也干等着？如果网络不好，A 发送消息发了 10 分钟还没到，B 就等 10 分钟？这工作严重不饱和，连传输信道都等得空虚寂寞冷了。那么，何以解之呢？

我么可以这么干：我们直接在发送端 A 和接收端 B 都开一个缓冲区，A 每次发送的消息都放在自己的缓冲区中，B 每次收到的消息也先放在自己的缓冲区中，A 只要缓冲区不满就继续发消息，直到缓冲区满为止；B 就循环从缓冲区取出消息处理，处理完就发送确认信息给 A，同时继续处理下一条消息；A 收到 B 的确认信号就从缓冲区移除对应的消息，移除之后缓冲区就不满了，就继续发送下一条消息。如此循环，直到消息全部发送完毕为止。

有人立刻就懂了，这不正是**生产者消费者模式**吗，没错，正是！

如此一来，我们的信道可能一直处于忙碌状态，大大提高了信道的利用率。假如，此刻，A 正在给 B 发送第 10 条消息，而 B 正好给 A 回复第 3 条消息的确认信息，此时信道中就同时出现 A 给 B 发、B 也给 A 发的情景，这正是全双工的表现。

那么，这样的话，就不是停止等待了，那这怎么保证对方来得及处理呢？

不不不，这仍然是停止等待，只不过等待的不是一条消息了，而是一堆消息了。换句话说，没有缓冲区的停止等待，就像有缓冲区但是缓冲区的大小是 1 的情况。有缓冲区的停止等待，等待的是什么呢？等待的是缓冲区不满，所以，当缓冲区满了，照样等待。

有人说，这也不对啊，没有缓冲区的停止等待，如果消息错了，我就重新发送，对方再重新处理就行了，而有了缓冲区后，如果中间一条消息出错了怎么办呢？后面的是不是全乱了？

对！后面的肯定都乱了，所以，后面的全部重新传送一遍即可！

比如，缓冲区大小是 5，A 发送了 12345，B 收到了 1245，没收到 3，那么，A 迟迟收不到 B 对 3 的确认信号，A 就会将 345 全部重新发送一遍，直到收到 3 的确认为止。

那如果 B 没收到 3，直接对 4 进行了处理，然后给 A 发送了 4 的确认呢？A 会认为这个确认无效，因为没跟上一个确认连上，所以不做处理。

有人又说了，你这如果中间丢了一个消息，就要把后面全部传送一遍，这效率肯定低了啊。

对，效率肯定低了，但是你想啊，我们的网络大部分都是好的，只有很少一部分时间是异常的，所以，这个选择肯定是利大于弊的。如果真的网络差，那也没办法，效率低是低了，但是消息还是正确的。总而言之，我们权衡利弊之后，还是选择带有缓冲区的停止等待协议。

其实，这个就叫做**连续 ARQ 协议**，大大提高了信道利用率，提高了传输效率。

### 连续 ARQ 协议

我们上面说了，使用加缓冲区的停止等待协议，就是连续 ARQ 协议，这其实就是采用流水线方式进行连续发送，提高信道利用率，而不用依次等待上一条消息的确认，毕竟异常的情况是少数，我们就默认是正常的，如果发现错误，再从错误的地方重新发送即可。

其实，连续 ARQ 协议是采用滑动窗口实现的，我们的缓冲区就等于一个窗口，如下所示：

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/699d8d8352d942c3974eba3e9393c559~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=355&h=228&s=11292&e=png&b=fdf3f1)

我们假设缓冲区的大小是 5，那么这个窗口的宽度也就是 5，我们把沿着滑动方向的两条边分别称为前沿和后沿，前沿后沿的差值就是缓冲区的大小；刚开始时，TCP 会将窗口内的消息全部发送，当收到一个确认信号时，窗口会整体向前移动，新进入窗口的消息就会被发送。

比如，图中所示，如果收到了消息 1 的确认，那么后沿就向前移动一个单位，如下：

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aca982c1f1154b518515d02a0b244e03~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=344&h=235&s=11589&e=png&b=fcf2f0)

此时，6 进入了窗口，6 就会被发送。如果此时收到了 2 的确认信号，窗口就继续向右边移动，直到全部确认为止。

窗口内的数据都是有缓存的，如果收不到确认，就会把窗口内的数据重新发送一遍。比如，如果超时没有收到 2 的确认，那么就会把窗口内的 23456 全部发送一遍（反正有缓存）；如果收到了 2 的确认，那么窗口整体右移，2 就被移出窗口，因为 2 不需要发送了。

这个过程就像窗口，所以也叫做**滑动窗口**。换句话说，连续 ARQ 协议是基于滑动窗口的思想实现的。

好，到这里，TCP 的数据传输我们都了解了。那么，TCP 是怎么建立连接的呢？

### 三次握手与四次挥手

**TCP 是怎么建立连接的呢？**

TCP 的连接采用 CS 模式，也叫做客户端-服务器模式，主动发起连接的叫客户端（C 端），被动等待连接的叫做服务端（S 端）。

刚开始客户端和服务端都处于关闭状态，当需要建立连接时，客户端会主动打开连接，然后请求服务器建立连接，这中间有`三次握手`的操作，如下。

1.  客户端：服务器吗，我需要建立连接（第一次握手）。
2.  服务器：朕知道了（第二次握手）。
3.  客户端：那还不赶紧打开（第三次握手）？
4.  服务器打开连接（建立连接）。

那么，为什么要三次握手呢？首先，不握手肯定是不行的，一次握手也是不行的，因为都不能保证对方收到了自己的请求，要保证对方收到了自己的请求，至少要两次握手，一次是请求，一次是对请求的确认。

我们知道，TCP 是全双工的，**如果只有两次握手，那么结果就是客户端发送、服务器确认，这只能保证服务器能接收到客户端的消息，而不能保证客户端能接收到服务器的消息，这是不可靠的**。所以我们需要三次握手，直到第三次客户端的应答过来了，才能保证客户端确确实实收到了服务器的确认信号，也就是保证了双方都能互相接收到对方的消息，也就保证了可靠性。

还有一点，就是可以**避免浪费资源**。比如：第一次握手时由于网络问题，发出的信号迟迟没有到达服务器，于是，由于超时重传，客户端再次发送一个连接信号，此时，网络中有两个连接信号了；如果这时候网络突然好了，那么服务器就会一下收到两个连接信号，如果是两次握手，服务器此时就直接打开了两个连接。这两个连接中必定有一个是无用的，白白浪费资源。

如果是三次握手呢？服务器就不会打开连接，而是发送两个确认信号给客户端，客户端收到第一个确认信号时，就告诉服务器打开连接（第三次握手），收到第二个确认信号时，由于已经收到过相同的信号了，就认为是重复的，就直接丢掉。这样服务器就只会收到一个第三次握手的信号，只会建立一个连接，从而避免浪费资源。

有人说，你这不就是让客户端判断是否有重复信号呗？你放在服务器不是也可以吗？

不可以！你要知道，服务器是面向多个客户端的，如果要判断是否有重复信号，那就要保存每一个客户端的请求信息，如果有 10 亿个客户端，这要保存多少信息呢？这个代价太高了，不如分摊到客户端，让客户端自己记录，这样代价低一些。所以，服务器适合做广播，而不太适合做单播。

所以，我们可以归纳三次握手的两个点：**保证可靠，避免浪费资源**。

那么，**TCP 是怎么断开连接呢？**

流程大致如下：

1.  客户端：我要断开了。
2.  服务器：好的。
3.  服务器：我也要断开了。
4.  客户端：好的。

这看着都费劲啊，就断个关系，吧啦吧啦还要四次，能不能干净利落点直接断了，就跟断开网线一样？

这肯定不行啊，如果直接断了，这到底是正常断开呢，还是网络异常了呢？所以我们需要通知对方，这就需要两次握手。而我们又知道，TCP 是全双工的，客户端到服务器断了就表示客户端不再向服务器发送消息了，但是，服务器依然可以向客户端发消息啊，因为你是全双工啊。所以，如果要彻底断开，还需要服务器发起一次握手，客户端进行一次应答，这样才能让这个全双工连接彻底断开。这就一共需要四次挥手。

有人说，那你连接的时候为啥三次就行？因为握手的时候，第二次握手的过程同时包含了服务器的应答和服务器的发送，等价于做了两件事，比如：

A：你能听到吗？

B：我能听到。（这句话说明 B 不但收到了 A 的消息，还表明了 B 能发送消息。）

A：好的。（这句话证明了 B 发消息成功，还证明了 A 能收到 B 的消息。）

多余的话就不扯了，到这里，相信你已经了解了其中的道理，那么，下次面试的时候，遇到这样的问题，希望你能把面试官吊起来挂在墙上打。

UDP 协议
------

**UDP 是无连接的、不可靠的**，所以没什么可以扯的太多的东西，这里就不废话了。

总结
--

本章重点讲解了 TCP 可靠传输的实现原理，以及 TCP 连接和断开的原理，我们再来回顾下。

*   TCP 要保证可靠，就要保证消息正确送达、接收方来得及处理。
*   通过超时重传来保证消息正确到达。
*   通过 ARQ 协议来保证接收方来得及处理，通过连续 ARQ 协议来提高信道利用率。
*   TCP 的连接需要三次握手，三次握手可以保证可靠性并且避免浪费资源。
*   TCP 的断开需要四次挥手，四次挥手可以保证全双工通信彻底断开。

这里面我们要学会两个思想：第一就是 **`动态策略思想`**，比如自适应自旋锁、超时等待协议的超时时间的计算，都是根据当前时机的情况动态调整策略；第二就是 **`滑动窗口思想`**，其实也等于缓冲区思想，当我们发现有等待的场景从而导致某种资源被白白浪费的时候，就可以开辟缓冲区，让等待者忙起来，先把产出结果放进缓冲区里面，从而避免浪费等待者这个资源。

好，下一节，我们就从实际开发的场景来看一下怎么优化我们的网络，以达到秒开、省流的目的。